---
title: "About"
date: "2020-08"
menu: main
sidebar: false
authorbox: false
---

# Description of the course

##  Skills of the learning program 

1) To acquire overview of the supply-chain of the data management (from production to analysis and results communication)  and be able to manage a data science project form end-to-end
2) To know methods and to apply tools for data handling, cleaning and requesting  
3) To know methods and to apply tools to explore and analyze data 
4) To know methods and to apply tools specific to data characterized by two specific dimensions of the industrial big data: spatial data and temporal data

## Organisation of the course

The course covers the whole issues of the data supply-chain: from data collection and production, storage and organization, management, exploitation and analysis, and communication. Big data and dynamic process of analysis needs transparent, repeatable and reproducible technics. Information and knowledge production will be presented 'backward' departing from the needs of decision tools.

The course is made of four parts on the following topics. Each of them aims, first, at identifying the needs of specific Big Data Management situations, and second, to give overview of the relevant methods and tools.

1)	**Big-Data Management**: Data Production and Storage rely on infrastructures and platform dedicated to the big data specificities. These are design to answer the needs of agility of the tools and of update of data. Repeatability, transparency and traceability of process will be discussed all along the data cleaning, querying and extraction operations.

2) **Exploration of complex data with high dimensionality**  (characterized by large number of variables of different natures, eventually structured and/or latent): Main methods of data exploration (classification, segmentation, etc.) will be presented from the IA, mathematics and statistics, and algorithmic  methods.

3)	**Analysis of complex data with temporal and / or spatial dimensions** (i.e. duration of process, duration between events - in the factory, in logistics, in consumer analysis, etc.): Duration data and temporal data methods will be presented like time series, survival analysis, and duration modeling.

4)	**Visualization  and communication**: Visualization  for big data exploration and results presentation will be discussed. Spatial dimension of big data will be explored using spatial data visualization  tools (geographical information system). All along the data management and analysis processes, attention will be paid to answer the needs, which means adopting an integrated view of the operations from data production to delivering the analysis using communication tools. Coordination and integration of tools will answer the needs of reproducibility, transparency of the processes.

Information and knowledge production will be presented ‘backward’
departing from the needs of decision tools. Hence, Visualization and Reporting will be the first step of the course, to raise questions of data architecture, handling, exploration and analysis.


![Data processing and analytics](Fig_1.png)

# Teachers and Industrial Contributors
## GI and Ensimag: 

  - *Christophe Bobineau*, MCF, Grenoble INP ENSIMAG
  - *Iragaël Joly* [^1], MCF HDR, Grenoble INP Génie industriel
  
[^1]: corresponding teacher: iragael.joly@grenoble-inp.fr

  - *Pierre Lemaire*, MCF, Grenoble INP Génie industriel
  - *Genoveva Vargas Solar*, DR, CNRS, LIG, HADAS Group 

## Invited Teachers: 
  - *Bruno Agard*, PR, Laboratoire en Intelligence des Données (LID), Département de Mathématiques et de Génie Industriel, École Polytechnique de Montréal
  - *Sylvie Charlot*, PR, GATE, Université Lyon 2


# Course Planning

Four parts are planned in $\approx 50h$ in the total class time. Each part is around $15h$. 
For each parts theoritical elements and applied data cases are planned.
Each lesson is planned as 3 hours lessons. Hence each part is $5 \times 3h$.

1. Vizualisation  
2. Big Data Architecture    
3. Big Data Exploration  
4. Geospatial Data Analysis  

# Detailed Program

| Topic              |  Details                                          |
|:-------------------|:-------------------------------------------------|
| **General Introduction** |  Introduction to the "BigData analytics" process|
|                      |	From the sensor and survey collection to the visualization of analytics results |
|                      |	Elements for a reproducible and transparent data analysis (introduced in the project sessions) |
|                      |  	          |
|                      |  	  ***        |
|                      |  	         |
| **PART I**            |  **Vizualisation** |       
| Reproducible report  |  Smart and efficient document edition | 
| Advanced visual  analytics           | Interactive GIS - Dismantle a map before to built one     |   
|  Decision tools      |  Dashboard, apps, etc.  |
|                      |  	          |
|                      |  	  ***        |
|                      |  	         |
| **PART II**            | **Big Data Architecture** |  
| *Distributed data management*| System definition and architecture; data distribution and sharding; distributed querying and map-reduce; Data models; distributed transactions |
|   3 sessions           |   Tools: MongoDB (ensimag), MongoDB sharding docker Population in USA|
|                      |   Hands on:  |
|                      |   HO1: Getting acquainted with MongoDB  |
|                      |   H02: Sharding with mongoDB http://vargas-solar.com/data-management-services-cloud/wp-content/uploads/sites/32/2015/01/Ex1-2Do2Handin.pdf   |
|                      |   |
| *Data engineering*  | profiling, cleaning and preparation on fragmented large data sets |
|                      |   Tools: Kaggle Data Lab (http://www.kaggle.com) Python networkx library, Neo4J graph querying (both on a docker container) |
|                      |   Data: Energy consumption data in Asia and in Europe  |
|                      |   Hands on:  |
|                      |   HO-3: Building samples using the k-fold technique) |
|                      |   HO-4: Facebook contacts for exploring graphs | http://vargas-solar.com/data-centric-smart-everything/network-analysis/ |
|                      |   |
| *Data processing and analytics at different scales* | Big Data Analytics Stacks and AI/ML studios |
|                      |   Tools: PySpark (docker) on Zeppelin, Azure ML Studio, Kaggle |
|                      |   Data: Configurations of Mercedes-Benz cars |
|                      |   Hands On:  |
|                      |   HO-5: https://www.kaggle.com/c/mercedes-benz-greener-manufacturing |
|                      |   HO-6: https://gallery.azure.ai/Experiment/Mercedes-time-in-testing-prediction |
|                      |   |
|                      |   |
|  *Application cases* |  **Smart-Grid Case**   |
|        Data | Metering and predicting household energy consumption and CO2 footprints. |
| ToDo: |  -	Prepare, distribute, query and analyze datasets containing energy consumption variables. |
|                      |  -	Use Big Data analytics environments for understanding the data and applying Mathematical (descriptive and inferential statistics, linear regression) and AI methods for generating energy consumption models using different perspectives. |
|                      |  	  ***        |
|                      |  	         |
| 	**PART III**            | **Big Data Exploration**  | 
|      *Segmentation*  |  Définitions. Notions de distances point à point, point à groupe, groupe |
|                      |  à groupe. Méthodes et algorithmes : de partitionnement (K-means, K-medoids,
|                      |  CLARA), hiérarchiques (CHA, CURE), basés sur la densité (DBSCAN), par grilles
|                      |  (STING, CLIQUE)
|                      |   |
|*Association rules*|  Définitions. Métriques. Génération de rêgles. Méthodes et  |
|                      |  algorithmes : A priori, A prioriTID, A priori Partition, comptage dynamique, FP-Tree, |
|                      |   RAM, random forest. Redondances des rêgles. |
|                      |   |
|*Decision Tree*  |  Classification automatique. Définitions. Construction d'arbres. Mesures d'impureté.   |
|                      |  Élagage, sur-apprentissage. Variables discrètes et variables continues. | 
|                      |  Données manquantes. Méthodes et algorithmes : CART, ID3, C4.5, SPRINT. Validation. | 
|                      |  Mesure de la qualité d'un partitionnement.            |
|                      |   |
|*Neural Network and*  |  Definitions. Perceptron : apprentissage par correction d'erreur |
| *Bayesian Network*   |  et par descente de gradient. Réseau multi-couches : apprentissage par |
|                      |  retropropagation du gradient. Détermination de modèles d'estimation |
|                      |  et de classification. Formule de Bayes. Classificateurs Bayésiens naïfs. |
|                      |  Validation.  |
|                      |   |
|  *Application cases* |  Conception et fabrication de produits. Traitement de gammes de production. |
|                      |  Amélioration des processus de production. Amélioration, gestion de la |
|                      |  qualité. Analyse de problèmes de non qualité. Systèmes de recommandations |
|                      |  	          |
|                      |  	  ***        |
|                      |  	         |
| **PART IV**            |  **Categorical, Temporal and Geospatial Data Analysis** |       
| *Categorical Data Analysis* |  Définitions (Binomial and Multinomial vector), Decision modeling and Data Analysis  |
|                   | Logistic regression, Multinomial logit, random parameter logit |
|                   | Ordered logit ; Sequential Logit ; Nested Logit  |
| *Temporal Data Analysis* |  Définitions (activités vs états ; Processus Markovien et semi-Markovien ). |
|                       | Modèle Markovien à mémoire, modèle de durée entre états |
|                      |  Données ordonnées, séquentielles, datée. Modélisation de l'ordre et du temps. |
|                      |  Séries temporelles, DTW et corrélation croisée. |
|                      |   |
|  *Geospatial Data Analysis*  |  Systèmes d'information géographique (Qgis et R) | 
|                      |  *Introduction to Cartography* (coordinnates, projections, semiology, etc.) |
|                      |  *Base de données spatiales* : couche de polygones, jointure entre données |
|                      | attributaires et spatiales |
|                      |  Position et attributs fixes et/ou variables.         |
|                      | *Analyse spatiale*:  Statistique descriptives spatiale |
|                      | Rélation et corrélation spatiale (notion de voisinage) |
|                      | Modèle gravitaire, modèle à auto-corrélation spatiale |
|                      |   |
|  *Application cases* | Industrial process events and duration analysis   |
|                      |   French Urban Mobilities patterns and time-use analysis| 


# Prerequisites  
Students will have to know and be able to demonstrate skills in:  
Knowledge in probability, statistics, introduction to data analysis, introduction to R language programming, relational database, declarative language SQL2.

If these elements are unknown by the student, teachers may decide to exclude them from the course (or under condition, may be requested to learn by themselves some of these elements)



![General Overview Diagram](Gen_overview.png)


# References

Ajouter des réf Architecture


---
\nocite: |
 @hayter2012, @Greene2008,@Greene2009, @Hougaard2000, @Lawless2003, @ListwonStPierre2013, @MaSeetharaman2004, @MartinussenScheike2006, @xie2015, @xie2016, @McFaddenTrain2000, @Train2009, @Agresti2013, @Kantardzic2011

Thanks for reading!
